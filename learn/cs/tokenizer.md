# TIL: Tokenizer를 활용한 문자열 분석

## Tokenizer와 문자열 분석
프로그래밍을 하다 보면 추상 구문 트리(AST)와 비슷한 자료구조를 만드는 경우가 있다. `JSON` `XML`처럼 형식이 있는 데이터를 분석해서 트리(tree) 구조로 만들기도 한다. 컴파일러 이론에서 복잡한 부분을 자세히 모르더라도 tokenizer, lexer, parser의 역할을 학습하는 것은 중요하다. 순서대로 토큰화를 거치고, 각 토큰의 어휘를 분석해서 의미를 부여하며, 문법을 체크한다.

## Tokenizer, Lexer, Parser의 역할
- **Tokenizer**: 입력된 문자열을 토큰 단위로 분리한다. 이 과정에서 공백이나 구두점 등을 제거하고 의미 있는 최소 단위로 나눈다.
- **Lexer**: Tokenizer의 결과물을 받아 각 토큰의 타입을 정의하고 어휘 분석을 수행한다. 이 단계에서는 토큰의 유효성도 검사한다.
- **Parser**: Lexer의 결과물을 바탕으로 문법 규칙에 따라 구조를 파악하고, 이를 바탕으로 추상 구문 트리(AST)를 생성한다. 이 과정에서 문법 오류를 발견하고 처리한다.

### Tokenizer에 대해 더 알아보기
Tokenizer는 컴파일러의 초기 단계에서 중요한 역할을 한다. 문자열을 의미 있는 단위인 토큰으로 분리하여 구문 분석(파싱)의 기초를 마련한다.

- **토큰화**: 문자열 입력을 받아 토큰의 연속으로 변환한다. 각 토큰은 프로그래밍 언어의 기본 단위(키워드, 식별자, 리터럴, 연산자 등)로 구성된다.
- **공백과 주석 제거**: 프로그래밍 언어에서 중요하지 않은 공백과 주석을 무시한다.
- **에러 처리**: 유효하지 않은 토큰을 발견하면 적절한 에러 메시지를 제공한다.

### 일반적인 토큰(Token) 종류
프로그래밍 언어에서 사용하는 토큰의 종류는 다음과 같다:
- **Identifier**: 식별하기 위한 이름
- **Keyword**: 미리 지정한 예약어
- **Separator**: 글자를 구분하는 문자
- **Operator**: 연산을 위한 심볼
- **Literal**: 숫자, 논리, 문자
- **Comment**: 줄 또는 블록 코멘터리

#### 토큰 예시

| 토큰이름  | 샘플                          |
|-----------|-------------------------------|
| identifier| HTML, BODY                    |
| separator | <, >, [, ], ,                 |
| operator  | +, <, =                       |
| literal   | true, NULL, 3.14, "hello"     |
| comment   | `<!코멘트는 무시>`            |

이러한 토큰들은 프로그래밍 언어에서 코드의 구성 요소를 정의하고 구분하는 데 사용된다. 각 토큰은 고유한 역할과 의미를 가지며, 이를 통해 컴파일러나 인터프리터가 코드를 분석하고 실행할 수 있다.

### Tokenizer의 역할
- **입력 스트림 처리**: 원시 코드 문자열을 읽어들이고, 이를 단위 토큰으로 분리한다.
- **어휘 분석**: 토큰의 타입을 식별하고 분류한다.
- **에러 보고**: 어휘 분석 과정에서 발견된 에러를 보고한다.
- **토큰 생성**: 파싱 과정에서 사용될 토큰 객체를 생성한다.

### Tokenizer와 컴파일러의 상호작용
- **토큰 공급자**: Tokenizer는 파서에게 토큰을 제공하는 역할을 한다. 파서는 Tokenizer로부터 받은 토큰을 이용해 문법 분석을 수행한다.
- **어휘 규칙**: 각 토큰의 정의는 프로그래밍 언어의 어휘 규칙에 따라 이루어진다. 예를 들어, 키워드, 식별자, 숫자 리터럴 등의 규칙이 있다.
- **스트림 관리**: Tokenizer는 입력 스트림을 효율적으로 관리하여, 필요 시 파서에게 다음 토큰을 제공한다.

